{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSCI 552 Final Project\n",
    "### Name : Anindita Ghosh\n",
    "### USC ID : 3898202691\n",
    "### GiHub ID : ghoshausc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import string,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model  \n",
    "from keras.layers import Dense, Flatten, Dropout,Activation, Input, LSTM\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Text Classification\n",
    "### It is highly recommended that you complete this project using Keras1 and Python. \n",
    "### (a) In this problem, we are trying to build a classifier to analyze the sentiment of reviews. You are provided with text data in two folders: one folder involves positive reviews, and one folder involves negative reviews. \n",
    "### (b) Data Exploration and Pre-processing \n",
    "### i. You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = −1 for negative sentiments.\n",
    "### ii. The data are pretty clean. Remove the punctuation and numbers from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first reading the data in each text files\n",
    "all_positive_reviews = []\n",
    "all_negative_reviews = []\n",
    "\n",
    "all_positive_reviews_folder = glob.glob(\"../data/pos/*\")\n",
    "for each_txt_file in all_positive_reviews_folder:\n",
    "    f = open(each_txt_file, \"r\")\n",
    "    review_in_each_file = f.read()\n",
    "    string_without_numbers = ''.join([string for string in review_in_each_file if not string.isdigit()])\n",
    "    string_without_punctuation = re.sub(r'[^\\w\\s]', '', string_without_numbers)                        #https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "    all_positive_reviews.append(string_without_punctuation)\n",
    "positive_responses = []\n",
    "    \n",
    "for i in range(len(all_positive_reviews)):\n",
    "    positive_responses.append(1)\n",
    "    \n",
    "\n",
    "negative_responses = []\n",
    "all_negative_reviews_folder = glob.glob(\"../data/neg/*\")\n",
    "for each_txt_file in all_negative_reviews_folder:\n",
    "    f = open(each_txt_file, \"r\")\n",
    "    review_in_each_file = f.read()\n",
    "    string_without_numbers = ''.join([string for string in review_in_each_file if not string.isdigit()])\n",
    "    string_without_punctuation = re.sub(r'[^\\w\\s]', '', string_without_numbers)                        #https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "    all_negative_reviews.append(string_without_punctuation)\n",
    "    \n",
    "for i in range(len(all_negative_reviews)):\n",
    "    negative_responses.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. The name of each text file starts with cv number. Use text files 0-699 in each class for training and 700-999 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making training and test dataframes\n",
    "\n",
    "training_df_values = all_positive_reviews[:700] + all_negative_reviews[:700]\n",
    "training_df_responses = positive_responses[:700] + negative_responses[:700]\n",
    "test_df_values = all_positive_reviews[700:1000] + all_negative_reviews[700:1000]\n",
    "test_df_responses = positive_responses[700:1000] + negative_responses[700:1000]\n",
    "\n",
    "for index,each_review in enumerate(training_df_values):\n",
    "    if \"\\n\" in each_review or each_review == \"\\n\":\n",
    "        training_df_values[index] = each_review.replace(\"\\n\",\"\")\n",
    "        \n",
    "for index,each_review in enumerate(test_df_values):\n",
    "    if \"\\n\" in each_review or each_review == \"\\n\":\n",
    "        test_df_values[index] = each_review.replace(\"\\n\",\"\")\n",
    "        \n",
    "while(\"\" in training_df_values) :\n",
    "    training_df_values.remove(\"\")\n",
    "while(\"\" in test_df_values) :\n",
    "    test_df_values.remove(\"\")\n",
    "    \n",
    "\n",
    "training_dataframe = pd.DataFrame({'Reviews' : training_df_values,'Response' : training_df_responses})\n",
    "test_dataframe = pd.DataFrame({'Reviews' : test_df_values,'Response' : test_df_responses})\n",
    "whole_dataframe = pd.concat([training_dataframe,test_dataframe])\n",
    "whole_dataframe_copy = whole_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>ahh yes  the teenage romance  an attractive yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>because im a scientist  thats what we do ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>written by david j  schow and john shirley  ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>one of my brothers favorite movies is h  b  ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>the premise of this movie is  well  pretty far...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  Response\n",
       "0     assume nothing  the phrase is perhaps one of t...         1\n",
       "1     plot  derek zoolander is a male model  he is a...         1\n",
       "2     i actually am a fan of the original  or so liv...         1\n",
       "3     a movie thats been as highly built up as the t...         1\n",
       "4       good will hunting  is two movies in one  an ...         1\n",
       "...                                                 ...       ...\n",
       "1395  ahh yes  the teenage romance  an attractive yo...         0\n",
       "1396       because im a scientist  thats what we do ...         0\n",
       "1397  written by david j  schow and john shirley  ba...         0\n",
       "1398  one of my brothers favorite movies is h  b  ha...         0\n",
       "1399  the premise of this movie is  well  pretty far...         0\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>directed by  pixote hunt  hendel butoy  eric g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minutes  not rated  though i suspect it would...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ingredients  lost parrot trying to get home  f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a scene early in soul food  george ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theres something about ben stiller that makes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response\n",
       "0    directed by  pixote hunt  hendel butoy  eric g...         1\n",
       "1     minutes  not rated  though i suspect it would...         1\n",
       "2    ingredients  lost parrot trying to get home  f...         1\n",
       "3    there is a scene early in soul food  george ti...         1\n",
       "4    theres something about ben stiller that makes ...         1\n",
       "..                                                 ...       ...\n",
       "595  synopsis  when a meteorite crashlands in the a...         0\n",
       "596  its now the anniversary of the slayings of jul...         0\n",
       "597  coinciding with the emerging popularity of mov...         0\n",
       "598  and now the highflying hong kong style of film...         0\n",
       "599  battlefield long  boring and just plain stupid...         0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response\n",
       "0    assume nothing  the phrase is perhaps one of t...         1\n",
       "1    plot  derek zoolander is a male model  he is a...         1\n",
       "2    i actually am a fan of the original  or so liv...         1\n",
       "3    a movie thats been as highly built up as the t...         1\n",
       "4      good will hunting  is two movies in one  an ...         1\n",
       "..                                                 ...       ...\n",
       "595  synopsis  when a meteorite crashlands in the a...         0\n",
       "596  its now the anniversary of the slayings of jul...         0\n",
       "597  coinciding with the emerging popularity of mov...         0\n",
       "598  and now the highflying hong kong style of film...         0\n",
       "599  battlefield long  boring and just plain stupid...         0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataframe_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Count the number of unique words in the whole dataset (train + test) and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for i in range(len(whole_dataframe_copy)):\n",
    "    words_in_review = whole_dataframe_copy[\"Reviews\"].iloc[i].strip().split(' ')\n",
    "    for index,each_word in enumerate(words_in_review):\n",
    "        if each_word!=\"\":\n",
    "            unique_words.add(each_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in the whole dataset is :  47037\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique words in the whole dataset is : \",len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engrosses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prolonged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gilfedder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47032</th>\n",
       "      <td>copes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47033</th>\n",
       "      <td>angered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47034</th>\n",
       "      <td>altitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47035</th>\n",
       "      <td>frequents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47036</th>\n",
       "      <td>seltzer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47037 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unique_Words\n",
       "0        confounds\n",
       "1        engrosses\n",
       "2        prolonged\n",
       "3        gilfedder\n",
       "4           delete\n",
       "...            ...\n",
       "47032        copes\n",
       "47033      angered\n",
       "47034     altitude\n",
       "47035    frequents\n",
       "47036      seltzer\n",
       "\n",
       "[47037 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_unique = 0\n",
    "dict_unique = {}\n",
    "for i,word in enumerate(unique_words):\n",
    "    dict_unique[i] = word\n",
    "unique_words_df = pd.DataFrame.from_dict(dict_unique,orient='index')\n",
    "unique_words_df.columns = [\"Unique_Words\"]\n",
    "unique_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Calculate the average review length and the standard deviation of review lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average review length is :  3728.3935  and the standard deviation of review lengths is : 1645.352819491325\n"
     ]
    }
   ],
   "source": [
    "#getting average review lengths as well as standard deviation\n",
    "\n",
    "# df['EventCount'] = df['Event'].str.split(\"/\").str.len()\n",
    "whole_dataframe_copy['Original_Review_Length'] = whole_dataframe['Reviews'].str.len()\n",
    "average_review_length = whole_dataframe_copy['Original_Review_Length'].mean()\n",
    "standard_deviation_review_length = whole_dataframe_copy['Original_Review_Length'].std()\n",
    "print(\"The average review length is : \",average_review_length,\" and the standard deviation of review lengths is :\",standard_deviation_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram Plot of Original Review Lengths')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(whole_dataframe_copy['Original_Review_Length'])\n",
    "plt.xlabel(\"Original Review Lengths\")\n",
    "plt.ylabel(\"Frequency of Original Review Lengths\")\n",
    "plt.title(\"Histogram Plot of Original Review Lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "      <td>9010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the story of us  a rob reiner film  is the sec...</td>\n",
       "      <td>1</td>\n",
       "      <td>4797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anastasia contains something that has been lac...</td>\n",
       "      <td>1</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the fighting sullivans  contains a major plo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>george little  jonathan lipnicki  wants a litt...</td>\n",
       "      <td>1</td>\n",
       "      <td>5575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>before you read my review  you gotta know that...</td>\n",
       "      <td>1</td>\n",
       "      <td>4448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>who would have thought  jim carrey does drama ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i rented  brokedown palace  last night blind  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the thoughtprovoking question of tradition ove...</td>\n",
       "      <td>1</td>\n",
       "      <td>6764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>first  i am not a big fan of the xfiles tv ser...</td>\n",
       "      <td>1</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>synopsis  committed to an asylum  the marquis ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>plot  a group of asbestos cleaners get a job r...</td>\n",
       "      <td>1</td>\n",
       "      <td>3697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>note that followups are directed to rec  arts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>meet joe black  reviewed on nov    starring br...</td>\n",
       "      <td>1</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i had lost all faith in pg movies that are int...</td>\n",
       "      <td>1</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i know what you did last summer   the first ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a standoff  a man holds a woman  a diplomats d...</td>\n",
       "      <td>1</td>\n",
       "      <td>3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>capsule  a rock and roll fable  indeed  like a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>what is freedom  how does one determine who is...</td>\n",
       "      <td>1</td>\n",
       "      <td>3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the blair witch project  was perhaps one of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>while screen adaptations of john irvings novel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hollywood is a pimp  a fat  cigarsmoking chump...</td>\n",
       "      <td>1</td>\n",
       "      <td>3429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>seen september    at  p  m  at the sony nickel...</td>\n",
       "      <td>1</td>\n",
       "      <td>6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i have to admit that i disliked this film init...</td>\n",
       "      <td>1</td>\n",
       "      <td>3803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the faculty   the heavilyhyped and advertise...</td>\n",
       "      <td>1</td>\n",
       "      <td>5288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "      <td>4035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>theres a moment in schindlers list when a numb...</td>\n",
       "      <td>1</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>in _daylight_  sylvester stallone breaks no ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>3199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bob the happy bastards quickie review  rush ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>synopsis  in this cultural exploration  a chin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>an astonishingly difficult movie to watch  the...</td>\n",
       "      <td>1</td>\n",
       "      <td>4398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Reviews  Response  \\\n",
       "0   assume nothing  the phrase is perhaps one of t...         1   \n",
       "1   plot  derek zoolander is a male model  he is a...         1   \n",
       "2   i actually am a fan of the original  or so liv...         1   \n",
       "3   a movie thats been as highly built up as the t...         1   \n",
       "4     good will hunting  is two movies in one  an ...         1   \n",
       "5   the story of us  a rob reiner film  is the sec...         1   \n",
       "6   anastasia contains something that has been lac...         1   \n",
       "7     the fighting sullivans  contains a major plo...         1   \n",
       "8   george little  jonathan lipnicki  wants a litt...         1   \n",
       "9   before you read my review  you gotta know that...         1   \n",
       "10  who would have thought  jim carrey does drama ...         1   \n",
       "11  i rented  brokedown palace  last night blind  ...         1   \n",
       "12  the thoughtprovoking question of tradition ove...         1   \n",
       "13  first  i am not a big fan of the xfiles tv ser...         1   \n",
       "14  synopsis  committed to an asylum  the marquis ...         1   \n",
       "15  plot  a group of asbestos cleaners get a job r...         1   \n",
       "16  note that followups are directed to rec  arts ...         1   \n",
       "17  meet joe black  reviewed on nov    starring br...         1   \n",
       "18  i had lost all faith in pg movies that are int...         1   \n",
       "19    i know what you did last summer   the first ...         1   \n",
       "20  a standoff  a man holds a woman  a diplomats d...         1   \n",
       "21  capsule  a rock and roll fable  indeed  like a...         1   \n",
       "22  what is freedom  how does one determine who is...         1   \n",
       "23    the blair witch project  was perhaps one of ...         1   \n",
       "24  while screen adaptations of john irvings novel...         1   \n",
       "25  hollywood is a pimp  a fat  cigarsmoking chump...         1   \n",
       "26  seen september    at  p  m  at the sony nickel...         1   \n",
       "27  i have to admit that i disliked this film init...         1   \n",
       "28    the faculty   the heavilyhyped and advertise...         1   \n",
       "29  films adapted from comic books have had plenty...         1   \n",
       "30  theres a moment in schindlers list when a numb...         1   \n",
       "31  in _daylight_  sylvester stallone breaks no ne...         1   \n",
       "32  bob the happy bastards quickie review  rush ho...         1   \n",
       "33  synopsis  in this cultural exploration  a chin...         1   \n",
       "34  an astonishingly difficult movie to watch  the...         1   \n",
       "\n",
       "    Original_Review_Length  \n",
       "0                     4426  \n",
       "1                     3600  \n",
       "2                     9010  \n",
       "3                     2281  \n",
       "4                     1761  \n",
       "5                     4797  \n",
       "6                     3010  \n",
       "7                     1434  \n",
       "8                     5575  \n",
       "9                     4448  \n",
       "10                    3817  \n",
       "11                   10150  \n",
       "12                    6764  \n",
       "13                    4411  \n",
       "14                    1754  \n",
       "15                    3697  \n",
       "16                    3725  \n",
       "17                    2280  \n",
       "18                    2799  \n",
       "19                    4142  \n",
       "20                    3163  \n",
       "21                    2149  \n",
       "22                    3058  \n",
       "23                    5829  \n",
       "24                    2533  \n",
       "25                    3429  \n",
       "26                    6784  \n",
       "27                    3803  \n",
       "28                    5288  \n",
       "29                    4035  \n",
       "30                    2694  \n",
       "31                    3199  \n",
       "32                    1672  \n",
       "33                    1696  \n",
       "34                    4398  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataframe_copy.head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii. To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be represented as 2, etc. Tokenize each text document using this method.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting words from each review\n",
    "\n",
    "list_of_all_reviews = whole_dataframe_copy['Reviews'].to_list()\n",
    "list_of_words_split_from_reviews = []\n",
    "for index,each_review in enumerate(list_of_all_reviews):\n",
    "    list_of_all_reviews[index] = each_review.lower()\n",
    "    review_split_to_words = each_review.lower().strip().split(\" \")\n",
    "    while(\"\" in review_split_to_words) :\n",
    "        review_split_to_words.remove(\"\")\n",
    "    list_of_words_split_from_reviews.append(review_split_to_words)\n",
    "# list_of_words_split_from_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned reviews without new lines, blanks and upper case.\n",
    "whole_dataframe_copy['Cleaned_Reviews'] = None\n",
    "for i in range(len(list_of_words_split_from_reviews)):\n",
    "    cleaned_review_str = ' '.join([str(elem) for elem in list_of_words_split_from_reviews[i]])\n",
    "    whole_dataframe_copy['Cleaned_Reviews'].iloc[i] = cleaned_review_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4426</td>\n",
       "      <td>assume nothing the phrase is perhaps one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>plot derek zoolander is a male model he is als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "      <td>9010</td>\n",
       "      <td>i actually am a fan of the original or so live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2281</td>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "      <td>good will hunting is two movies in one an inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>synopsis when a meteorite crashlands in the ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "      <td>2976</td>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "      <td>2706</td>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "      <td>3962</td>\n",
       "      <td>battlefield long boring and just plain stupid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response  \\\n",
       "0    assume nothing  the phrase is perhaps one of t...         1   \n",
       "1    plot  derek zoolander is a male model  he is a...         1   \n",
       "2    i actually am a fan of the original  or so liv...         1   \n",
       "3    a movie thats been as highly built up as the t...         1   \n",
       "4      good will hunting  is two movies in one  an ...         1   \n",
       "..                                                 ...       ...   \n",
       "595  synopsis  when a meteorite crashlands in the a...         0   \n",
       "596  its now the anniversary of the slayings of jul...         0   \n",
       "597  coinciding with the emerging popularity of mov...         0   \n",
       "598  and now the highflying hong kong style of film...         0   \n",
       "599  battlefield long  boring and just plain stupid...         0   \n",
       "\n",
       "     Original_Review_Length                                    Cleaned_Reviews  \n",
       "0                      4426  assume nothing the phrase is perhaps one of th...  \n",
       "1                      3600  plot derek zoolander is a male model he is als...  \n",
       "2                      9010  i actually am a fan of the original or so live...  \n",
       "3                      2281  a movie thats been as highly built up as the t...  \n",
       "4                      1761  good will hunting is two movies in one an inde...  \n",
       "..                      ...                                                ...  \n",
       "595                    1864  synopsis when a meteorite crashlands in the ar...  \n",
       "596                    2976  its now the anniversary of the slayings of jul...  \n",
       "597                    1688  coinciding with the emerging popularity of mov...  \n",
       "598                    2706  and now the highflying hong kong style of film...  \n",
       "599                    3962  battlefield long boring and just plain stupid ...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataframe_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the data\n",
    "tokenized_data = []\n",
    "for i in whole_dataframe_copy['Cleaned_Reviews'].iteritems():\n",
    "    data_seq = i[1]\n",
    "    data_seq_split = i[1].split()\n",
    "    \n",
    "    # creating the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    \n",
    "    # fit the tokenizer on the split data sequences\n",
    "    tokenizer.fit_on_texts(data_seq_split)\n",
    "    \n",
    "    # sort the data sequences\n",
    "    data_sort = sorted(tokenizer.word_counts.items(), key=lambda x:x[1],reverse = True)\n",
    "\n",
    "    # Cleaning the data\n",
    "    clean_data = []\n",
    "    for i in range(len(data_sort)):\n",
    "        clean_data.append((data_sort[i][0], i+1))\n",
    "        i =i+1\n",
    "\n",
    "    for x in clean_data:\n",
    "        data_seq = re.sub(r\"\\b%s\\b\" % x[0] , str(x[1]), data_seq)\n",
    "    \n",
    "    data_seq = data_seq.split(' ')\n",
    "    data_seq = [p for p in data_seq if p.isdigit()]\n",
    "    data_seq = ' '.join(data_seq).split()\n",
    "    tokenized_data.append(data_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viii. Select a review length L that 70% of the reviews have a length below it. If you feel more adventurous, set the threshold to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length L :  737\n"
     ]
    }
   ],
   "source": [
    "list_of_cleaned_reviews_with_length_sorted = sorted(list_of_words_split_from_reviews, key=len)\n",
    "#selecting a review length as required\n",
    "required_lenght_of_review = len(list_of_cleaned_reviews_with_length_sorted[int(70/100*len(whole_dataframe_copy))])\n",
    "print(\"Review length L : \",required_lenght_of_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataframe_copy['L'] = None\n",
    "for index,each_review in enumerate(list_of_words_split_from_reviews):\n",
    "    whole_dataframe_copy['L'].iloc[index] = len(each_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4426</td>\n",
       "      <td>assume nothing the phrase is perhaps one of th...</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>plot derek zoolander is a male model he is als...</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "      <td>9010</td>\n",
       "      <td>i actually am a fan of the original or so live...</td>\n",
       "      <td>1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2281</td>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "      <td>good will hunting is two movies in one an inde...</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>synopsis when a meteorite crashlands in the ar...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "      <td>2976</td>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "      <td>2706</td>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "      <td>3962</td>\n",
       "      <td>battlefield long boring and just plain stupid ...</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response  \\\n",
       "0    assume nothing  the phrase is perhaps one of t...         1   \n",
       "1    plot  derek zoolander is a male model  he is a...         1   \n",
       "2    i actually am a fan of the original  or so liv...         1   \n",
       "3    a movie thats been as highly built up as the t...         1   \n",
       "4      good will hunting  is two movies in one  an ...         1   \n",
       "..                                                 ...       ...   \n",
       "595  synopsis  when a meteorite crashlands in the a...         0   \n",
       "596  its now the anniversary of the slayings of jul...         0   \n",
       "597  coinciding with the emerging popularity of mov...         0   \n",
       "598  and now the highflying hong kong style of film...         0   \n",
       "599  battlefield long  boring and just plain stupid...         0   \n",
       "\n",
       "     Original_Review_Length  \\\n",
       "0                      4426   \n",
       "1                      3600   \n",
       "2                      9010   \n",
       "3                      2281   \n",
       "4                      1761   \n",
       "..                      ...   \n",
       "595                    1864   \n",
       "596                    2976   \n",
       "597                    1688   \n",
       "598                    2706   \n",
       "599                    3962   \n",
       "\n",
       "                                       Cleaned_Reviews     L  \n",
       "0    assume nothing the phrase is perhaps one of th...   790  \n",
       "1    plot derek zoolander is a male model he is als...   616  \n",
       "2    i actually am a fan of the original or so live...  1589  \n",
       "3    a movie thats been as highly built up as the t...   423  \n",
       "4    good will hunting is two movies in one an inde...   278  \n",
       "..                                                 ...   ...  \n",
       "595  synopsis when a meteorite crashlands in the ar...   302  \n",
       "596  its now the anniversary of the slayings of jul...   528  \n",
       "597  coinciding with the emerging popularity of mov...   270  \n",
       "598  and now the highflying hong kong style of film...   451  \n",
       "599  battlefield long boring and just plain stupid ...   698  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataframe_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ix. Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Reviews_Truncated_Zero_Padded = tf.keras.preprocessing.sequence.pad_sequences(tokenized_data, maxlen = 737, truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>L</th>\n",
       "      <th>Cleaned_Reviews_Truncated_Zero_Padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4426</td>\n",
       "      <td>assume nothing the phrase is perhaps one of th...</td>\n",
       "      <td>790</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>plot derek zoolander is a male model he is als...</td>\n",
       "      <td>616</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "      <td>9010</td>\n",
       "      <td>i actually am a fan of the original or so live...</td>\n",
       "      <td>1589</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2281</td>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>423</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "      <td>good will hunting is two movies in one an inde...</td>\n",
       "      <td>278</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>synopsis when a meteorite crashlands in the ar...</td>\n",
       "      <td>302</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "      <td>2976</td>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>528</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>270</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "      <td>2706</td>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>451</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "      <td>3962</td>\n",
       "      <td>battlefield long boring and just plain stupid ...</td>\n",
       "      <td>698</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response  \\\n",
       "0    assume nothing  the phrase is perhaps one of t...         1   \n",
       "1    plot  derek zoolander is a male model  he is a...         1   \n",
       "2    i actually am a fan of the original  or so liv...         1   \n",
       "3    a movie thats been as highly built up as the t...         1   \n",
       "4      good will hunting  is two movies in one  an ...         1   \n",
       "..                                                 ...       ...   \n",
       "595  synopsis  when a meteorite crashlands in the a...         0   \n",
       "596  its now the anniversary of the slayings of jul...         0   \n",
       "597  coinciding with the emerging popularity of mov...         0   \n",
       "598  and now the highflying hong kong style of film...         0   \n",
       "599  battlefield long  boring and just plain stupid...         0   \n",
       "\n",
       "     Original_Review_Length  \\\n",
       "0                      4426   \n",
       "1                      3600   \n",
       "2                      9010   \n",
       "3                      2281   \n",
       "4                      1761   \n",
       "..                      ...   \n",
       "595                    1864   \n",
       "596                    2976   \n",
       "597                    1688   \n",
       "598                    2706   \n",
       "599                    3962   \n",
       "\n",
       "                                       Cleaned_Reviews     L  \\\n",
       "0    assume nothing the phrase is perhaps one of th...   790   \n",
       "1    plot derek zoolander is a male model he is als...   616   \n",
       "2    i actually am a fan of the original or so live...  1589   \n",
       "3    a movie thats been as highly built up as the t...   423   \n",
       "4    good will hunting is two movies in one an inde...   278   \n",
       "..                                                 ...   ...   \n",
       "595  synopsis when a meteorite crashlands in the ar...   302   \n",
       "596  its now the anniversary of the slayings of jul...   528   \n",
       "597  coinciding with the emerging popularity of mov...   270   \n",
       "598  and now the highflying hong kong style of film...   451   \n",
       "599  battlefield long boring and just plain stupid ...   698   \n",
       "\n",
       "                 Cleaned_Reviews_Truncated_Zero_Padded  \n",
       "0    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "2    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "3    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "4    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "..                                                 ...  \n",
       "595  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "596  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "597  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "598  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "599  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataframe_copy['Cleaned_Reviews_Truncated_Zero_Padded'] = None\n",
    "for i in range(len(whole_dataframe_copy)):\n",
    "    whole_dataframe_copy['Cleaned_Reviews_Truncated_Zero_Padded'].iloc[i] = Cleaned_Reviews_Truncated_Zero_Padded\n",
    "whole_dataframe_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the training and the test dataframe after all the preprocessing.\n",
    "\n",
    "training_df_preprocessed = whole_dataframe_copy.iloc[:1400]\n",
    "test_df_preprocessed = whole_dataframe_copy.iloc[1400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>L</th>\n",
       "      <th>Cleaned_Reviews_Truncated_Zero_Padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing  the phrase is perhaps one of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4426</td>\n",
       "      <td>assume nothing the phrase is perhaps one of th...</td>\n",
       "      <td>790</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot  derek zoolander is a male model  he is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>plot derek zoolander is a male model he is als...</td>\n",
       "      <td>616</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original  or so liv...</td>\n",
       "      <td>1</td>\n",
       "      <td>9010</td>\n",
       "      <td>i actually am a fan of the original or so live...</td>\n",
       "      <td>1589</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2281</td>\n",
       "      <td>a movie thats been as highly built up as the t...</td>\n",
       "      <td>423</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting  is two movies in one  an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "      <td>good will hunting is two movies in one an inde...</td>\n",
       "      <td>278</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>ahh yes  the teenage romance  an attractive yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>3541</td>\n",
       "      <td>ahh yes the teenage romance an attractive youn...</td>\n",
       "      <td>600</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>because im a scientist  thats what we do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5289</td>\n",
       "      <td>because im a scientist thats what we do dr ale...</td>\n",
       "      <td>958</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>written by david j  schow and john shirley  ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>3524</td>\n",
       "      <td>written by david j schow and john shirley base...</td>\n",
       "      <td>589</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>one of my brothers favorite movies is h  b  ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>2908</td>\n",
       "      <td>one of my brothers favorite movies is h b hali...</td>\n",
       "      <td>513</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>the premise of this movie is  well  pretty far...</td>\n",
       "      <td>0</td>\n",
       "      <td>2668</td>\n",
       "      <td>the premise of this movie is well pretty farfe...</td>\n",
       "      <td>466</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  Response  \\\n",
       "0     assume nothing  the phrase is perhaps one of t...         1   \n",
       "1     plot  derek zoolander is a male model  he is a...         1   \n",
       "2     i actually am a fan of the original  or so liv...         1   \n",
       "3     a movie thats been as highly built up as the t...         1   \n",
       "4       good will hunting  is two movies in one  an ...         1   \n",
       "...                                                 ...       ...   \n",
       "1395  ahh yes  the teenage romance  an attractive yo...         0   \n",
       "1396       because im a scientist  thats what we do ...         0   \n",
       "1397  written by david j  schow and john shirley  ba...         0   \n",
       "1398  one of my brothers favorite movies is h  b  ha...         0   \n",
       "1399  the premise of this movie is  well  pretty far...         0   \n",
       "\n",
       "      Original_Review_Length  \\\n",
       "0                       4426   \n",
       "1                       3600   \n",
       "2                       9010   \n",
       "3                       2281   \n",
       "4                       1761   \n",
       "...                      ...   \n",
       "1395                    3541   \n",
       "1396                    5289   \n",
       "1397                    3524   \n",
       "1398                    2908   \n",
       "1399                    2668   \n",
       "\n",
       "                                        Cleaned_Reviews     L  \\\n",
       "0     assume nothing the phrase is perhaps one of th...   790   \n",
       "1     plot derek zoolander is a male model he is als...   616   \n",
       "2     i actually am a fan of the original or so live...  1589   \n",
       "3     a movie thats been as highly built up as the t...   423   \n",
       "4     good will hunting is two movies in one an inde...   278   \n",
       "...                                                 ...   ...   \n",
       "1395  ahh yes the teenage romance an attractive youn...   600   \n",
       "1396  because im a scientist thats what we do dr ale...   958   \n",
       "1397  written by david j schow and john shirley base...   589   \n",
       "1398  one of my brothers favorite movies is h b hali...   513   \n",
       "1399  the premise of this movie is well pretty farfe...   466   \n",
       "\n",
       "                  Cleaned_Reviews_Truncated_Zero_Padded  \n",
       "0     [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1     [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "2     [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "3     [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "4     [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "...                                                 ...  \n",
       "1395  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1396  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1397  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1398  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1399  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Response</th>\n",
       "      <th>Original_Review_Length</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>L</th>\n",
       "      <th>Cleaned_Reviews_Truncated_Zero_Padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>directed by  pixote hunt  hendel butoy  eric g...</td>\n",
       "      <td>1</td>\n",
       "      <td>4180</td>\n",
       "      <td>directed by pixote hunt hendel butoy eric gold...</td>\n",
       "      <td>674</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minutes  not rated  though i suspect it would...</td>\n",
       "      <td>1</td>\n",
       "      <td>6517</td>\n",
       "      <td>minutes not rated though i suspect it would be...</td>\n",
       "      <td>1072</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ingredients  lost parrot trying to get home  f...</td>\n",
       "      <td>1</td>\n",
       "      <td>3255</td>\n",
       "      <td>ingredients lost parrot trying to get home fri...</td>\n",
       "      <td>544</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a scene early in soul food  george ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>3069</td>\n",
       "      <td>there is a scene early in soul food george til...</td>\n",
       "      <td>555</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theres something about ben stiller that makes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3178</td>\n",
       "      <td>theres something about ben stiller that makes ...</td>\n",
       "      <td>506</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>synopsis  when a meteorite crashlands in the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>synopsis when a meteorite crashlands in the ar...</td>\n",
       "      <td>302</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>0</td>\n",
       "      <td>2976</td>\n",
       "      <td>its now the anniversary of the slayings of jul...</td>\n",
       "      <td>528</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>270</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>0</td>\n",
       "      <td>2706</td>\n",
       "      <td>and now the highflying hong kong style of film...</td>\n",
       "      <td>451</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>battlefield long  boring and just plain stupid...</td>\n",
       "      <td>0</td>\n",
       "      <td>3962</td>\n",
       "      <td>battlefield long boring and just plain stupid ...</td>\n",
       "      <td>698</td>\n",
       "      <td>[[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  Response  \\\n",
       "0    directed by  pixote hunt  hendel butoy  eric g...         1   \n",
       "1     minutes  not rated  though i suspect it would...         1   \n",
       "2    ingredients  lost parrot trying to get home  f...         1   \n",
       "3    there is a scene early in soul food  george ti...         1   \n",
       "4    theres something about ben stiller that makes ...         1   \n",
       "..                                                 ...       ...   \n",
       "595  synopsis  when a meteorite crashlands in the a...         0   \n",
       "596  its now the anniversary of the slayings of jul...         0   \n",
       "597  coinciding with the emerging popularity of mov...         0   \n",
       "598  and now the highflying hong kong style of film...         0   \n",
       "599  battlefield long  boring and just plain stupid...         0   \n",
       "\n",
       "     Original_Review_Length  \\\n",
       "0                      4180   \n",
       "1                      6517   \n",
       "2                      3255   \n",
       "3                      3069   \n",
       "4                      3178   \n",
       "..                      ...   \n",
       "595                    1864   \n",
       "596                    2976   \n",
       "597                    1688   \n",
       "598                    2706   \n",
       "599                    3962   \n",
       "\n",
       "                                       Cleaned_Reviews     L  \\\n",
       "0    directed by pixote hunt hendel butoy eric gold...   674   \n",
       "1    minutes not rated though i suspect it would be...  1072   \n",
       "2    ingredients lost parrot trying to get home fri...   544   \n",
       "3    there is a scene early in soul food george til...   555   \n",
       "4    theres something about ben stiller that makes ...   506   \n",
       "..                                                 ...   ...   \n",
       "595  synopsis when a meteorite crashlands in the ar...   302   \n",
       "596  its now the anniversary of the slayings of jul...   528   \n",
       "597  coinciding with the emerging popularity of mov...   270   \n",
       "598  and now the highflying hong kong style of film...   451   \n",
       "599  battlefield long boring and just plain stupid ...   698   \n",
       "\n",
       "                 Cleaned_Reviews_Truncated_Zero_Padded  \n",
       "0    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "1    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "2    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "3    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "4    [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "..                                                 ...  \n",
       "595  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "596  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "597  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "598  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "599  [[111, 112, 1, 38, 2, 113, 21, 5, 1, 58, 59, 5...  \n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (c) Word Embeddings\n",
    "### i. One can use tokenized text as inputs to a deep neural network. However, a recent breakthrough in NLP suggests that more sophisticated representations of text yield better results. These sophisticated representations are called word embeddings. “Word embedding is a term used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.”4. Most deep learning modules (including Keras) provide a convenient way to convert positive integer representations of words into a word embedding by an “Embedding layer.” The layer accepts arguments that define the mapping of words into embeddings, including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value). The layer also allows you to specify the dimension for each word vector, called the “output dimension.” We would like to use a word embedding layer for this project. Assume that we are interested in the top 5,000 words. This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000 words in the document.5 If you feel more adventurous, use all the words that appear in this corpus. Choose the length of the embedding vector for each word to be 32. Hence, each document is represented as a 32 × L matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Embedding Model\n",
    "model_keras_word_encoding = Sequential()\n",
    "model_keras_word_encoding.add(Input(required_lenght_of_review))\n",
    "model_keras_word_encoding.add(Embedding(5000, 32, input_length=required_lenght_of_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 737, 32)           160000    \n",
      "=================================================================\n",
      "Total params: 160,000\n",
      "Trainable params: 160,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras_word_encoding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ii. Flatten the matrix of each document to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 23584)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras_word_encoding.add(Flatten(input_shape=(32, required_lenght_of_review)))\n",
    "model_keras_word_encoding.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 737, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 23584)             0         \n",
      "=================================================================\n",
      "Total params: 160,000\n",
      "Trainable params: 160,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras_word_encoding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Multi-Layer Perceptron \n",
    "### i. Train a MLP with three (dense) hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Use a dropout rate of 20% for the first layer and 50% for the other layers. Use ADAM optimizer and binary cross entropy loss (which is equivalent to having a softmax in the output). To avoid overfitting, just set the number of epochs as 2. Use a batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 737, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 23584)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1179250   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,344,401\n",
      "Trainable params: 1,344,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP model \n",
    "model_keras_word_encoding.add(Dense(50))\n",
    "model_keras_word_encoding.add(Activation('relu'))\n",
    "model_keras_word_encoding.add(Dropout(0.2))\n",
    "model_keras_word_encoding.add(Dense(50))\n",
    "model_keras_word_encoding.add(Activation('relu'))\n",
    "model_keras_word_encoding.add(Dropout(0.5))\n",
    "model_keras_word_encoding.add(Dense(50))\n",
    "model_keras_word_encoding.add(Activation('relu'))\n",
    "model_keras_word_encoding.add(Dropout(0.5))\n",
    "model_keras_word_encoding.add(Dense(1))\n",
    "model_keras_word_encoding.add(Activation('sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model_keras_word_encoding.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# summarize the model\n",
    "model_keras_word_encoding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 737)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating X and Y of train and test data\n",
    "# X_train = training_df_preprocessed['Cleaned_Reviews_Truncated_Zero_Padded'].values\n",
    "Cleaned_Reviews_Truncated_Zero_Padded = np.array(Cleaned_Reviews_Truncated_Zero_Padded)\n",
    "X_train = Cleaned_Reviews_Truncated_Zero_Padded[:1400,:]\n",
    "X_test = Cleaned_Reviews_Truncated_Zero_Padded[1400:,:]\n",
    "\n",
    "y_train = training_df_preprocessed['Response']\n",
    "y_test = test_df_preprocessed['Response']\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.6980\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.6632\n"
     ]
    }
   ],
   "source": [
    "#training the MLP model\n",
    "model_mlp_train = model_keras_word_encoding.fit(X_train,\n",
    "                                                y_train,\n",
    "                                                epochs=2,\n",
    "                                                batch_size=10,\n",
    "                                                verbose=1,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for the MLP model is :  0.85785717\n"
     ]
    }
   ],
   "source": [
    "y_predicted_mlp = model_keras_word_encoding.predict(X_train)\n",
    "y_predicted_mlp = np.where(y_predicted_mlp<0.5,0,1)\n",
    "\n",
    "mlp_accuracy = tf.keras.metrics.Accuracy()\n",
    "mlp_accuracy.update_state(y_train, y_predicted_mlp)\n",
    "print('Training Accuracy for the MLP model is : ', mlp_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for the MLP model is :  0.50166667\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "y_predicted_mlp_test = model_keras_word_encoding.predict(X_test)\n",
    "y_predicted_mlp_test = np.where(y_predicted_mlp_test<0.5,0,1)\n",
    "\n",
    "mlp_accuracy_test = tf.keras.metrics.Accuracy()\n",
    "mlp_accuracy_test.update_state(y_test, y_predicted_mlp_test)\n",
    "print('Test Accuracy for the MLP model is : ', mlp_accuracy_test.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss and Train Accurracy of the MLP model are : \n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4898\n",
      "\n",
      " Test Loss and Test Accurracy of the MLP model are : \n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6960471272468567"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating training loss\n",
    "print('Training Loss and Train Accurracy of the MLP model are : ') \n",
    "model_keras_word_encoding.evaluate(X_train,y_train,verbose=1)\n",
    "\n",
    "# Evaluating test loss\n",
    "print('\\n Test Loss and Test Accurracy of the MLP model are : ')\n",
    "model_keras_word_encoding.evaluate(X_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) One-Dimensional Convolutional Neural Network: Although CNNs are mainly used for image data, they can also be applied to text data, as text also has adjacency information. Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively. \n",
    "### i. After the embedding layer, insert a Conv1D layer. This convolutional layer has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded word representations 3 vector elements of the word embedding at a time. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 737, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 735, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 367, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11744)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                587250    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 755,505\n",
      "Trainable params: 755,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(tf.keras.layers.Embedding(5000, 32, input_length=required_lenght_of_review))\n",
    "cnn_model.add(tf.keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "cnn_model.add(tf.keras.layers.Flatten(input_shape=(16, required_lenght_of_review)))\n",
    "cnn_model.add(Dense(50))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Dense(50))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(50))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.add(Activation('sigmoid'))\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0634\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0193\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0225\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0053\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0163\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0087\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0102\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0066\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0059\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0200\n"
     ]
    }
   ],
   "source": [
    "#training the CNN model\n",
    "model_cnn_train = cnn_model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=10,\n",
    "                    verbose = 1,\n",
    "                    shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for the CNN model is :  0.99714285\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "y_predicted_cnn = cnn_model.predict(X_train)\n",
    "y_predicted_cnn = np.where(y_predicted_cnn<0.5,0,1)\n",
    "\n",
    "cnn_accuracy = tf.keras.metrics.Accuracy()\n",
    "cnn_accuracy.update_state(y_train, y_predicted_cnn)\n",
    "print('Training Accuracy for the CNN model is : ', cnn_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for the CNN model is :  0.5183333\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "y_predicted_cnn_test = cnn_model.predict(X_test)\n",
    "y_predicted_cnn_test = np.where(y_predicted_cnn_test<0.5,0,1)\n",
    "\n",
    "cnn_accuracy_test = tf.keras.metrics.Accuracy()\n",
    "cnn_accuracy_test.update_state(y_test, y_predicted_cnn_test)\n",
    "print('Test Accuracy for the CNN model is : ', cnn_accuracy_test.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for the CNN model is : \n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "\n",
      " Test Loss for the CNN model is : \n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.7801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.780069589614868"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating training loss\n",
    "print('Training Loss for the CNN model is : ') \n",
    "cnn_model.evaluate(X_train,y_train,verbose=1)\n",
    "\n",
    "# Evaluating test loss\n",
    "print('\\n Test Loss for the CNN model is : ')\n",
    "cnn_model.evaluate(X_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Long Short-Term Memory Recurrent Neural Network: The structure of the LSTM we are going to use is shown in the following figure.\n",
    "### i. Each word is represented to LSTM as a vector of 32 elements and the LSTM is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both LSTM and the dense layer. Train the model using 10-50 epochs and batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 737, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 32, input_length = int(required_lenght_of_review)))\n",
    "lstm_model.add(LSTM(32))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(256, activation = 'relu'))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1, activation = 'sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.5090\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5106\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 17s 118ms/step - loss: 0.5216\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4919\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4863\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4888\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 16s 114ms/step - loss: 0.4882\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 17s 124ms/step - loss: 0.4883\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4852\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4836\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4799\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4812\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 16s 111ms/step - loss: 0.4925\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 17s 119ms/step - loss: 0.4863\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4893\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4865\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4787\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4778\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4794\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 16s 112ms/step - loss: 0.4812\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 17s 119ms/step - loss: 0.4801\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4775\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4715\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4890\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4808\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 16s 114ms/step - loss: 0.4745\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 0.4730\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 16s 113ms/step - loss: 0.4686\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4658\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4740\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 16s 111ms/step - loss: 0.4702\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 0.5008\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.4890\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 16s 116ms/step - loss: 0.4709\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 17s 124ms/step - loss: 0.4640\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 16s 113ms/step - loss: 0.4671\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4650\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.4627\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4598\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.4784\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 14s 103ms/step - loss: 0.4741\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4881\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 15s 110ms/step - loss: 0.4745\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 16s 117ms/step - loss: 0.4748\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4741\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.4711\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.4633\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 17s 118ms/step - loss: 0.4612\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 18s 127ms/step - loss: 0.4588\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 15s 109ms/step - loss: 0.4598\n"
     ]
    }
   ],
   "source": [
    "model_lstm_train = lstm_model.fit(X_train,\n",
    "                                  y_train,\n",
    "                                  epochs=50,\n",
    "                                  batch_size=10,\n",
    "                                  verbose = 1,\n",
    "                                  shuffle=True\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for the CNN model is :  0.69285715\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "y_predicted_lstm = lstm_model.predict(X_train)\n",
    "y_predicted_lstm = np.where(y_predicted_lstm<0.5,0,1)\n",
    "\n",
    "lstm_accuracy = tf.keras.metrics.Accuracy()\n",
    "lstm_accuracy.update_state(y_train, y_predicted_lstm)\n",
    "print('Training Accuracy for the CNN model is : ', lstm_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for the CNN model is :  0.5233333\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "y_predicted_lstm_test = lstm_model.predict(X_test)\n",
    "y_predicted_lstm_test = np.where(y_predicted_lstm_test<0.5,0,1)\n",
    "\n",
    "lstm_accuracy_test = tf.keras.metrics.Accuracy()\n",
    "lstm_accuracy_test.update_state(y_test, y_predicted_lstm_test)\n",
    "print('Test Accuracy for the CNN model is : ', lstm_accuracy_test.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for the LSTM model is : \n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.4554\n",
      "\n",
      " Test Loss for the LSTM model is : \n",
      "19/19 [==============================] - 0s 24ms/step - loss: 2.4589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4589037895202637"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating training loss\n",
    "print('Training Loss for the LSTM model is : ') \n",
    "lstm_model.evaluate(X_train,y_train,verbose=1)\n",
    "\n",
    "# Evaluating test loss\n",
    "print('\\n Test Loss for the LSTM model is : ')\n",
    "lstm_model.evaluate(X_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
